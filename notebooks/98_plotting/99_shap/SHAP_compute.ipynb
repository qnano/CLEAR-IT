{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f71a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from clearit.config import MODELS_DIR, DATASETS_DIR, OUTPUTS_DIR\n",
    "from clearit.metrics.gather_test_results import get_classifier_test_results\n",
    "from clearit.inference.pipeline import load_encoder_head\n",
    "from clearit.shap.utils import load_model_from_test, get_dataloader_for_shap\n",
    "from clearit.shap.explainer import prepare_shap_explainer\n",
    "from clearit.shap.compute import compute_shap_values_batch, smooth_shap_maps\n",
    "from clearit.shap.io import build_shap_metadata, save_shap_bundle\n",
    "from clearit.plotting.shap import plot_shap_heatmaps\n",
    "from clearit.io.select import select_cells_by_outcome_and_confidence\n",
    "from clearit.io.classification_report import classification_report\n",
    "import platform, torch, shap as _shap, numpy as _np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d79ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ID to analyze - T0030 contains linear evaluation results for the best encoder/classifier pair obtained in round 2 for TNBC1-MxIF8 + TME-A_ML6\n",
    "test_id = \"T0030\"\n",
    "\n",
    "# Specify dataset and annotations (we explicitly define these here, but they can also be obtained from test_conf.yaml)\n",
    "dataset_name = \"TNBC1-MxIF8\"\n",
    "annotation_name = \"TME-A_ML6\"\n",
    "\n",
    "# Load labels and class strings\n",
    "df_all = pd.read_csv(Path(DATASETS_DIR, dataset_name, annotation_name, \"labels.csv\"))\n",
    "class_strings = pd.read_csv(Path(DATASETS_DIR, dataset_name, annotation_name, \"class_names.csv\"))[\"name\"].tolist()\n",
    "markers = class_strings  # alias\n",
    "\n",
    "# Specify channel names and order for plotting\n",
    "channel_strings_desired = ['DAPI', 'CK', 'CD3', 'CD8', 'CD20', 'CD56', 'CD68', 'AF']\n",
    "desired_channel_order = [0, 1, 2, 4, 6, 5, 3, 7]\n",
    "\n",
    "# Define what we will loop over and how many cells to sample for the respective prediction type\n",
    "confidence_orders = [\"highest\", \"lowest\"]\n",
    "outcomes = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "num_per_marker = 100\n",
    "\n",
    "# Output setup\n",
    "output_dir = Path(OUTPUTS_DIR,\"shap\",dataset_name,annotation_name,test_id,f\"N{num_per_marker:04d}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "master_report_entries = []\n",
    "\n",
    "# Build test results\n",
    "df_test_results = get_classifier_test_results(test_id, df_all, class_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94eda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[encoder] missing=2 unexpected=4\n",
      "  eg missing: ['main_backbone.fc.weight', 'main_backbone.fc.bias']\n",
      "  eg unexpected: ['mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias']\n",
      "[encoder] checkpoint has no fc weights -> using Identity fc to match old training\n",
      "[head] strict load ok.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TP_highest.npz, SHAP_TP_highest.csv.gz, SHAP_TP_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TP_lowest.npz, SHAP_TP_lowest.csv.gz, SHAP_TP_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TN_highest.npz, SHAP_TN_highest.csv.gz, SHAP_TN_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TN_lowest.npz, SHAP_TN_lowest.csv.gz, SHAP_TN_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FP_highest.npz, SHAP_FP_highest.csv.gz, SHAP_FP_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FP_lowest.npz, SHAP_FP_lowest.csv.gz, SHAP_FP_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FN_highest.npz, SHAP_FN_highest.csv.gz, SHAP_FN_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FN_lowest.npz, SHAP_FN_lowest.csv.gz, SHAP_FN_lowest.yaml\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the exact model used in the test\n",
    "model, test_cfg, head_cfg = load_model_from_test(test_id, device=device)\n",
    "\n",
    "# Use head_cfg to drive shapes/metadata\n",
    "num_classes = int(head_cfg[\"num_classes\"])\n",
    "patch_size  = int(head_cfg.get(\"img_size\", 64))\n",
    "dataset_name = head_cfg[\"dataset_name\"]           \n",
    "\n",
    "# If df_test_results lacks the raw 'label' column, merge it from df_all once:\n",
    "if \"label\" not in df_test_results.columns:\n",
    "    df_test_results = df_test_results.merge(\n",
    "        df_all[[\"fname\", \"cell_x\", \"cell_y\", \"label\"]],\n",
    "        on=[\"fname\", \"cell_x\", \"cell_y\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "SAVE_SMOOTHED = False     # save the SHAP values unsmoothed\n",
    "\n",
    "for outcome in outcomes:\n",
    "    for order in confidence_orders:\n",
    "        df_filtered = select_cells_by_outcome_and_confidence(\n",
    "            df_test_results, markers=markers, outcome=outcome, order=order, num_per_marker=num_per_marker\n",
    "        )\n",
    "        if df_filtered.empty:\n",
    "            continue\n",
    "\n",
    "        loader, _ = get_dataloader_for_shap(\n",
    "            df_filtered,\n",
    "            dataset_name=dataset_name,\n",
    "            patch_size=patch_size,\n",
    "            label_mode=\"multilabel\",\n",
    "            num_classes=num_classes,\n",
    "            batch_size=64,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        explainer, background, sample_in = prepare_shap_explainer(\n",
    "            model, loader, device=device, background_strategy=\"zeros\"\n",
    "        )\n",
    "\n",
    "        shap_values, _ = compute_shap_values_batch(\n",
    "            explainer, loader, device=device, check_additivity=False\n",
    "        )\n",
    "\n",
    "        # Optionally smooth now; otherwise keep raw and smooth when plotting\n",
    "        if SAVE_SMOOTHED:\n",
    "            shap_values_to_save = smooth_shap_maps(shap_values, sigma=SMOOTH_SIGMA)\n",
    "        else:\n",
    "            shap_values_to_save = shap_values\n",
    "\n",
    "        # Build metadata for this condition\n",
    "        selection = {\"outcome\": outcome, \"order\": order, \"num_per_marker\": int(num_per_marker)}\n",
    "        background_md = {\"strategy\": \"zeros\", \"num_batches\": 1}\n",
    "        shap_md = {\n",
    "            \"check_additivity\": False,\n",
    "            \"smoothed\": bool(SAVE_SMOOTHED),\n",
    "            \"sigma\": float(SMOOTH_SIGMA) if SAVE_SMOOTHED else None,\n",
    "            \"array_shape\": tuple(shap_values_to_save.shape),\n",
    "            \"array_dtype\": str(shap_values_to_save.dtype),\n",
    "        }\n",
    "        meta = build_shap_metadata(\n",
    "            test_id=test_id,\n",
    "            dataset_name=dataset_name,\n",
    "            annotation_name=annotation_name,\n",
    "            head_cfg=head_cfg,\n",
    "            selection=selection,\n",
    "            channel_strings=channel_strings_desired,\n",
    "            class_strings=class_strings,\n",
    "            desired_channel_order=desired_channel_order,\n",
    "            background=background_md,\n",
    "            shap_config=shap_md,\n",
    "        )\n",
    "\n",
    "        # Save under a stable, discoverable name\n",
    "        base = output_dir / f\"SHAP_{outcome}_{order}\"\n",
    "        paths = save_shap_bundle(base, shap_values_to_save, df_filtered, meta, dtype=\"float32\", compressed=True)\n",
    "        print(f\"Saved bundle: {paths['npz'].name}, {paths['table'].name}, {paths['yaml'].name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432f6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ID to analyze - T0030 contains linear evaluation results for the best encoder/classifier pair obtained in round 2 for TNBC2-MIBI8 + TME-A_ML6\n",
    "test_id = \"T0129\"\n",
    "\n",
    "# Specify dataset and annotations (we explicitly define these here, but they can also be obtained from test_conf.yaml)\n",
    "dataset_name = \"TNBC2-MIBI/TNBC2-MIBI8\"\n",
    "annotation_name = \"TME-A_ML6\"\n",
    "\n",
    "# Load labels and class strings\n",
    "df_all = pd.read_csv(Path(DATASETS_DIR, dataset_name, annotation_name, \"labels.csv\"))\n",
    "class_strings = pd.read_csv(Path(DATASETS_DIR, dataset_name, annotation_name, \"class_names.csv\"))[\"name\"].tolist()\n",
    "markers = class_strings  # alias\n",
    "\n",
    "# Specify channel names and order for plotting\n",
    "channel_strings_desired = ['dsDNA', 'Pan-Keratin', 'CD3', 'CD8', 'CD20', 'CD56', 'CD68', 'BG']\n",
    "desired_channel_order = [0, 1, 2, 4, 6, 5, 3, 7]\n",
    "\n",
    "# Define what we will loop over and how many cells to sample for the respective prediction type\n",
    "confidence_orders = [\"highest\", \"lowest\"]\n",
    "outcomes = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "num_per_marker = 100\n",
    "\n",
    "# Output setup\n",
    "output_dir = Path(OUTPUTS_DIR,\"shap\",dataset_name,annotation_name,test_id,f\"N{num_per_marker:04d}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "master_report_entries = []\n",
    "\n",
    "# Build test results\n",
    "df_test_results = get_classifier_test_results(test_id, df_all, class_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5f1d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[encoder] missing=2 unexpected=4\n",
      "  eg missing: ['main_backbone.fc.weight', 'main_backbone.fc.bias']\n",
      "  eg unexpected: ['mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias']\n",
      "[encoder] checkpoint has no fc weights -> using Identity fc to match old training\n",
      "[head] strict load ok.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TP_highest.npz, SHAP_TP_highest.csv.gz, SHAP_TP_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TP_lowest.npz, SHAP_TP_lowest.csv.gz, SHAP_TP_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TN_highest.npz, SHAP_TN_highest.csv.gz, SHAP_TN_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_TN_lowest.npz, SHAP_TN_lowest.csv.gz, SHAP_TN_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FP_highest.npz, SHAP_FP_highest.csv.gz, SHAP_FP_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FP_lowest.npz, SHAP_FP_lowest.csv.gz, SHAP_FP_lowest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FN_highest.npz, SHAP_FN_highest.csv.gz, SHAP_FN_highest.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unrecognized nn.Module: Identity\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bundle: SHAP_FN_lowest.npz, SHAP_FN_lowest.csv.gz, SHAP_FN_lowest.yaml\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the exact model used in the test\n",
    "model, test_cfg, head_cfg = load_model_from_test(test_id, device=device)\n",
    "\n",
    "# Use head_cfg to drive shapes/metadata\n",
    "num_classes = int(head_cfg[\"num_classes\"])\n",
    "patch_size  = int(head_cfg.get(\"img_size\", 64))\n",
    "dataset_name = head_cfg[\"dataset_name\"]           \n",
    "\n",
    "# If df_test_results lacks the raw 'label' column, merge it from df_all once:\n",
    "if \"label\" not in df_test_results.columns:\n",
    "    df_test_results = df_test_results.merge(\n",
    "        df_all[[\"fname\", \"cell_x\", \"cell_y\", \"label\"]],\n",
    "        on=[\"fname\", \"cell_x\", \"cell_y\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "SAVE_SMOOTHED = False     # save the SHAP values unsmoothed\n",
    "\n",
    "for outcome in outcomes:\n",
    "    for order in confidence_orders:\n",
    "        df_filtered = select_cells_by_outcome_and_confidence(\n",
    "            df_test_results, markers=markers, outcome=outcome, order=order, num_per_marker=num_per_marker\n",
    "        )\n",
    "        if df_filtered.empty:\n",
    "            continue\n",
    "\n",
    "        loader, _ = get_dataloader_for_shap(\n",
    "            df_filtered,\n",
    "            dataset_name=dataset_name,\n",
    "            patch_size=patch_size,\n",
    "            label_mode=\"multilabel\",\n",
    "            num_classes=num_classes,\n",
    "            batch_size=64,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        explainer, background, sample_in = prepare_shap_explainer(\n",
    "            model, loader, device=device, background_strategy=\"zeros\"\n",
    "        )\n",
    "\n",
    "        shap_values, _ = compute_shap_values_batch(\n",
    "            explainer, loader, device=device, check_additivity=False\n",
    "        )\n",
    "\n",
    "        # Optionally smooth now; otherwise keep raw and smooth when plotting\n",
    "        if SAVE_SMOOTHED:\n",
    "            shap_values_to_save = smooth_shap_maps(shap_values, sigma=SMOOTH_SIGMA)\n",
    "        else:\n",
    "            shap_values_to_save = shap_values\n",
    "\n",
    "        # Build metadata for this condition\n",
    "        selection = {\"outcome\": outcome, \"order\": order, \"num_per_marker\": int(num_per_marker)}\n",
    "        background_md = {\"strategy\": \"zeros\", \"num_batches\": 1}\n",
    "        shap_md = {\n",
    "            \"check_additivity\": False,\n",
    "            \"smoothed\": bool(SAVE_SMOOTHED),\n",
    "            \"sigma\": float(SMOOTH_SIGMA) if SAVE_SMOOTHED else None,\n",
    "            \"array_shape\": tuple(shap_values_to_save.shape),\n",
    "            \"array_dtype\": str(shap_values_to_save.dtype),\n",
    "        }\n",
    "        meta = build_shap_metadata(\n",
    "            test_id=test_id,\n",
    "            dataset_name=dataset_name,\n",
    "            annotation_name=annotation_name,\n",
    "            head_cfg=head_cfg,\n",
    "            selection=selection,\n",
    "            channel_strings=channel_strings_desired,\n",
    "            class_strings=class_strings,\n",
    "            desired_channel_order=desired_channel_order,\n",
    "            background=background_md,\n",
    "            shap_config=shap_md,\n",
    "        )\n",
    "\n",
    "        # Save under a stable, discoverable name\n",
    "        base = output_dir / f\"SHAP_{outcome}_{order}\"\n",
    "        paths = save_shap_bundle(base, shap_values_to_save, df_filtered, meta, dtype=\"float32\", compressed=True)\n",
    "        print(f\"Saved bundle: {paths['npz'].name}, {paths['table'].name}, {paths['yaml'].name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
